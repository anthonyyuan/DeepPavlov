{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can also run the notebook in [COLAB](https://colab.research.google.com/github/deepmipt/DeepPavlov/blob/master/examples/gobot_tutorial.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:20.324 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from my_data/dstc2-trn.jsonlist]\n",
      "2019-08-06 14:38:20.480 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from my_data/dstc2-val.jsonlist]\n",
      "2019-08-06 14:38:20.590 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from my_data/dstc2-tst.jsonlist]\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.dataset_readers.dstc2_reader import DSTC2DatasetReader\n",
    "\n",
    "data = DSTC2DatasetReader().read('my_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'cheap restaurant',\n",
       "  'intents': [{'slots': [['pricerange', 'cheap']], 'act': 'inform'}]},\n",
       " {'text': 'What kind of food would you like?', 'act': 'request_food'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deeppavlov.dataset_iterators.dialog_iterator import DialogDatasetIterator\n",
    "\n",
    "iterator = DialogDatasetIterator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '', 'intents': [], 'prev_resp_act': None},\n",
       " {'text': 'cheap restaurant',\n",
       "  'intents': [{'slots': [['pricerange', 'cheap']], 'act': 'inform'}],\n",
       "  'prev_resp_act': 'welcomemsg'},\n",
       " {'text': 'any',\n",
       "  'intents': [{'slots': [['this', 'dontcare']], 'act': 'inform'}],\n",
       "  'prev_resp_act': 'request_food'},\n",
       " {'text': 'south',\n",
       "  'intents': [{'slots': [['area', 'south']], 'act': 'inform'}],\n",
       "  'prev_resp_act': 'request_area'},\n",
       " {'text': 'south',\n",
       "  'intents': [{'slots': [['area', 'south']], 'act': 'inform'}],\n",
       "  'db_result': {'food': 'chinese',\n",
       "   'pricerange': 'cheap',\n",
       "   'area': 'south',\n",
       "   'addr': 'cambridge leisure park clifton way cherry hinton',\n",
       "   'phone': '01223 244277',\n",
       "   'postcode': 'c.b 1, 7 d.y',\n",
       "   'name': 'the lucky star'},\n",
       "  'prev_resp_act': 'api_call'},\n",
       " {'text': 'address',\n",
       "  'intents': [{'slots': [['slot', 'addr']], 'act': 'request'}],\n",
       "  'prev_resp_act': 'inform_area+inform_food+offer_name'},\n",
       " {'text': 'phone number',\n",
       "  'intents': [{'slots': [['slot', 'phone']], 'act': 'request'}],\n",
       "  'prev_resp_act': 'inform_addr+offer_name'},\n",
       " {'text': 'thank you good bye',\n",
       "  'intents': [{'slots': [], 'act': 'thankyou'}, {'slots': [], 'act': 'bye'}],\n",
       "  'prev_resp_act': 'inform_phone+offer_name'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dialog, y_dialog = iterator.train[0]\n",
    "x_dialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build database of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:23.369 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 47: No load path is set for Sqlite3Database in 'infer' mode. Using save path instead\n",
      "2019-08-06 14:38:23.370 INFO in 'deeppavlov.core.data.sqlite_database'['sqlite_database'] at line 63: Loading database from /home/vimary/code-projects/Pilot/examples/my_bot/db.sqlite.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.data.sqlite_database import Sqlite3Database\n",
    "\n",
    "database = Sqlite3Database(table_name=\"mytable\",\n",
    "                           primary_keys=[\"name\"],\n",
    "                           keys=[\"name\", \"food\", \"pricerange\", \"area\", \"addr\", \"phone\", \"postcode\"],\n",
    "                           save_path=\"my_bot/db.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 3016 items.\n"
     ]
    }
   ],
   "source": [
    "db_results = []\n",
    "for dialog in iterator.gen_batches(batch_size=1, data_type='all'):\n",
    "    turns_x, turns_y = dialog\n",
    "    db_results.extend(x['db_result'] for x in turns_x[0] if x.get('db_result'))\n",
    "\n",
    "print(f\"Adding {len(db_results)} items.\")\n",
    "if db_results:\n",
    "    database.fit(db_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'nandos',\n",
       "   'food': 'portuguese',\n",
       "   'pricerange': 'cheap',\n",
       "   'area': 'south',\n",
       "   'addr': 'cambridge leisure park clifton way',\n",
       "   'phone': '01223 327908',\n",
       "   'postcode': 'c.b 1, 7 d.y'},\n",
       "  {'name': 'the lucky star',\n",
       "   'food': 'chinese',\n",
       "   'pricerange': 'cheap',\n",
       "   'area': 'south',\n",
       "   'addr': 'cambridge leisure park clifton way cherry hinton',\n",
       "   'phone': '01223 244277',\n",
       "   'postcode': 'c.b 1, 7 d.y'}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database([{'pricerange': 'cheap', 'area': 'south'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db.sqlite\r\n"
     ]
    }
   ],
   "source": [
    "!ls my_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Slot Filler\n",
    "\n",
    "Slot Filler is component that takes text as input and outputs dictionary of slot names and their values:\n",
    "\n",
    "    slot_filler(['I would like some chineese food'])\n",
    "    >> [{'food': 'chinese'}]\n",
    "\n",
    "To implement a slot filler you need to provide\n",
    "    \n",
    " - **slot types**\n",
    " - all possible **slot values**\n",
    " - optionally, it will be good to provide examples of mentions for every value of a slot\n",
    " \n",
    "The data should be provided in `slot_vals.json` file with the following format:\n",
    "\n",
    "    {\n",
    "        'food': {\n",
    "            'chinese': ['chinese', 'chineese', 'chines'],\n",
    "            'french': ['french', 'freench'],\n",
    "            'dontcare': ['any food', '\n",
    "                \n",
    "\n",
    "There are two possible models for a slot filler:\n",
    "\n",
    "   1. A non-trainable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import configs\n",
    "from deeppavlov.core.common.file import read_json\n",
    "\n",
    "ner_config = read_json(configs.ner.ner_dstc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_config['dataset_iterator']['download'] = False\n",
    "ner_config['metadata']['variables']['DATA_PATH'] = 'my_data'\n",
    "\n",
    "ner_config['metadata']['variables']['MODEL_PATH'] = 'my_bot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:27.897 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /home/vimary/code-projects/Pilot/examples/my_data/dstc2-trn.jsonlist]\n",
      "2019-08-06 14:38:28.82 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /home/vimary/code-projects/Pilot/examples/my_data/dstc2-val.jsonlist]\n",
      "2019-08-06 14:38:28.226 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 112: [loading dialogs from /home/vimary/code-projects/Pilot/examples/my_data/dstc2-tst.jsonlist]\n",
      "[nltk_data] Downloading package punkt to /home/vimary/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/vimary/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/vimary/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/vimary/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "2019-08-06 14:38:29.626 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 98: [saving vocabulary to /home/vimary/code-projects/Pilot/examples/my_bot/word.dict]\n",
      "2019-08-06 14:38:29.636 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 98: [saving vocabulary to /home/vimary/code-projects/Pilot/examples/my_bot/tag.dict]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 14:38:30.427729 139782432462464 deprecation_wrapper.py:119] From /home/vimary/code-projects/Pilot/deeppavlov/core/models/tf_model.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0806 14:38:30.428516 139782432462464 deprecation_wrapper.py:119] From /home/vimary/code-projects/Pilot/deeppavlov/core/models/tf_model.py:223: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 14:38:30.428882 139782432462464 deprecation_wrapper.py:119] From /home/vimary/code-projects/Pilot/deeppavlov/core/models/tf_model.py:223: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Using TensorFlow backend.\n",
      "W0806 14:38:30.453928 139782432462464 deprecation_wrapper.py:119] From /home/vimary/code-projects/Pilot/deeppavlov/models/ner/network.py:96: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "W0806 14:38:30.454723 139782432462464 deprecation_wrapper.py:119] From /home/vimary/code-projects/Pilot/deeppavlov/core/models/tf_model.py:194: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0806 14:38:30.460834 139782432462464 deprecation_wrapper.py:119] From /home/vimary/code-projects/Pilot/deeppavlov/models/ner/network.py:170: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0806 14:38:30.473448 139782432462464 deprecation.py:506] From /home/vimary/code-projects/Pilot/deeppavlov/core/layers/tf_layers.py:948: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0806 14:38:30.481615 139782432462464 deprecation.py:323] From /home/vimary/code-projects/Pilot/deeppavlov/core/layers/tf_layers.py:66: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "W0806 14:38:30.542884 139782432462464 deprecation.py:323] From /home/vimary/code-projects/Pilot/deeppavlov/core/layers/tf_layers.py:69: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0806 14:38:30.657052 139782432462464 deprecation.py:323] From /home/vimary/code-projects/Pilot/deeppavlov/models/ner/network.py:248: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0806 14:38:30.935535 139782432462464 deprecation.py:323] From /home/vimary/code-projects/Pilot/deeppavlov/models/ner/network.py:259: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "W0806 14:38:30.950922 139782432462464 deprecation_wrapper.py:119] From /home/vimary/code-projects/Pilot/deeppavlov/core/models/tf_model.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0806 14:38:31.131128 139782432462464 deprecation.py:323] From /home/vimary/dp_env/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0806 14:38:32.024201 139782432462464 deprecation.py:323] From /home/vimary/code-projects/Pilot/deeppavlov/core/models/tf_model.py:51: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2019-08-06 14:38:32.953 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 6673 phrases; correct: 0.\n",
      "\n",
      "precision:  2.41%; recall:  84.29%; FB1:  4.69\n",
      "\n",
      "\tpricerange: precision:  2.41%; recall:  84.29%; F1:  4.69 6673\n",
      "\n",
      "\n",
      "I0806 14:38:32.953718 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 6673 phrases; correct: 0.\n",
      "\n",
      "precision:  2.41%; recall:  84.29%; FB1:  4.69\n",
      "\n",
      "\tpricerange: precision:  2.41%; recall:  84.29%; F1:  4.69 6673\n",
      "\n",
      "\n",
      "2019-08-06 14:38:32.955 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 164: New best ner_f1 of 4.6911\n",
      "I0806 14:38:32.955759 139782432462464 nn_trainer.py:164] New best ner_f1 of 4.6911\n",
      "2019-08-06 14:38:32.956 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 166: Saving model\n",
      "I0806 14:38:32.956486 139782432462464 nn_trainer.py:166] Saving model\n",
      "2019-08-06 14:38:32.957 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 76: [saving model to /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "I0806 14:38:32.957746 139782432462464 tf_model.py:76] [saving model to /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "W0806 14:38:32.958556 139782432462464 deprecation_wrapper.py:119] From /home/vimary/code-projects/Pilot/deeppavlov/core/models/tf_model.py:78: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 4.6911, \"per_token_accuracy\": 0.2234}, \"time_spent\": \"0:00:01\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:33.741 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 457 tokens with 7 phrases; found: 7 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 7\n",
      "\n",
      "\n",
      "I0806 14:38:33.741576 139782432462464 fmeasure.py:390] processed 457 tokens with 7 phrases; found: 7 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:02\", \"epochs_done\": 3, \"batches_seen\": 100, \"train_examples_seen\": 6247, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.009858857964118214}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:34.44 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "I0806 14:38:34.044127 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "2019-08-06 14:38:34.45 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 164: New best ner_f1 of 99.2208\n",
      "I0806 14:38:34.045793 139782432462464 nn_trainer.py:164] New best ner_f1 of 99.2208\n",
      "2019-08-06 14:38:34.46 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 166: Saving model\n",
      "I0806 14:38:34.046424 139782432462464 nn_trainer.py:166] Saving model\n",
      "2019-08-06 14:38:34.47 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 76: [saving model to /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "I0806 14:38:34.047497 139782432462464 tf_model.py:76] [saving model to /home/vimary/code-projects/Pilot/examples/my_bot/model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.2208, \"per_token_accuracy\": 0.9996}, \"time_spent\": \"0:00:03\", \"epochs_done\": 5, \"batches_seen\": 155, \"train_examples_seen\": 9665, \"impatience\": 0, \"patience_limit\": 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:34.361 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 361 tokens with 13 phrases; found: 13 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 13\n",
      "\n",
      "\n",
      "I0806 14:38:34.361689 139782432462464 fmeasure.py:390] processed 361 tokens with 13 phrases; found: 13 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 13\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:03\", \"epochs_done\": 6, \"batches_seen\": 200, \"train_examples_seen\": 12494, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 0.00013358064141812066}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:34.827 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 385 tokens with 6 phrases; found: 6 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
      "\n",
      "\n",
      "I0806 14:38:34.827815 139782432462464 fmeasure.py:390] processed 385 tokens with 6 phrases; found: 6 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
      "\n",
      "\n",
      "2019-08-06 14:38:34.931 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "I0806 14:38:34.931679 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "2019-08-06 14:38:34.933 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 170: Did not improve on the ner_f1 of 99.2208\n",
      "I0806 14:38:34.933311 139782432462464 nn_trainer.py:170] Did not improve on the ner_f1 of 99.2208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:03\", \"epochs_done\": 9, \"batches_seen\": 300, \"train_examples_seen\": 18741, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 4.4304569955784244e-05}}\n",
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.2208, \"per_token_accuracy\": 0.9996}, \"time_spent\": \"0:00:03\", \"epochs_done\": 10, \"batches_seen\": 310, \"train_examples_seen\": 19330, \"impatience\": 1, \"patience_limit\": 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:35.364 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 418 tokens with 10 phrases; found: 10 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 10\n",
      "\n",
      "\n",
      "I0806 14:38:35.364089 139782432462464 fmeasure.py:390] processed 418 tokens with 10 phrases; found: 10 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:04\", \"epochs_done\": 12, \"batches_seen\": 400, \"train_examples_seen\": 24988, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 2.482367179140965e-05}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:35.732 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 193 phrases; correct: 0.\n",
      "\n",
      "precision:  98.96%; recall:  100.00%; FB1:  99.48\n",
      "\n",
      "\tpricerange: precision:  98.96%; recall:  100.00%; F1:  99.48 193\n",
      "\n",
      "\n",
      "I0806 14:38:35.732610 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 193 phrases; correct: 0.\n",
      "\n",
      "precision:  98.96%; recall:  100.00%; FB1:  99.48\n",
      "\n",
      "\tpricerange: precision:  98.96%; recall:  100.00%; F1:  99.48 193\n",
      "\n",
      "\n",
      "2019-08-06 14:38:35.734 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 164: New best ner_f1 of 99.4792\n",
      "I0806 14:38:35.734609 139782432462464 nn_trainer.py:164] New best ner_f1 of 99.4792\n",
      "2019-08-06 14:38:35.735 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 166: Saving model\n",
      "I0806 14:38:35.735409 139782432462464 nn_trainer.py:166] Saving model\n",
      "2019-08-06 14:38:35.736 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 76: [saving model to /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "I0806 14:38:35.736883 139782432462464 tf_model.py:76] [saving model to /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "2019-08-06 14:38:36.19 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 402 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 9\n",
      "\n",
      "\n",
      "I0806 14:38:36.019383 139782432462464 fmeasure.py:390] processed 402 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.4792, \"per_token_accuracy\": 0.9998}, \"time_spent\": \"0:00:04\", \"epochs_done\": 15, \"batches_seen\": 465, \"train_examples_seen\": 28995, \"impatience\": 0, \"patience_limit\": 5}}\n",
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:04\", \"epochs_done\": 16, \"batches_seen\": 500, \"train_examples_seen\": 31184, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 1.9916872644643036e-05}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:36.495 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 419 tokens with 8 phrases; found: 8 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
      "\n",
      "\n",
      "I0806 14:38:36.495473 139782432462464 fmeasure.py:390] processed 419 tokens with 8 phrases; found: 8 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 8\n",
      "\n",
      "\n",
      "2019-08-06 14:38:36.640 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "I0806 14:38:36.640517 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "2019-08-06 14:38:36.642 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 170: Did not improve on the ner_f1 of 99.4792\n",
      "I0806 14:38:36.642480 139782432462464 nn_trainer.py:170] Did not improve on the ner_f1 of 99.4792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:05\", \"epochs_done\": 19, \"batches_seen\": 600, \"train_examples_seen\": 37431, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 1.20993732841157e-05}}\n",
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.2208, \"per_token_accuracy\": 0.9996}, \"time_spent\": \"0:00:05\", \"epochs_done\": 20, \"batches_seen\": 620, \"train_examples_seen\": 38660, \"impatience\": 1, \"patience_limit\": 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:37.40 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 350 tokens with 6 phrases; found: 6 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
      "\n",
      "\n",
      "I0806 14:38:37.040794 139782432462464 fmeasure.py:390] processed 350 tokens with 6 phrases; found: 6 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:06\", \"epochs_done\": 22, \"batches_seen\": 700, \"train_examples_seen\": 43678, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 9.790402919236384e-06}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:37.453 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "I0806 14:38:37.453161 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "2019-08-06 14:38:37.454 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 170: Did not improve on the ner_f1 of 99.4792\n",
      "I0806 14:38:37.454668 139782432462464 nn_trainer.py:170] Did not improve on the ner_f1 of 99.4792\n",
      "2019-08-06 14:38:37.589 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 375 tokens with 7 phrases; found: 7 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 7\n",
      "\n",
      "\n",
      "I0806 14:38:37.589651 139782432462464 fmeasure.py:390] processed 375 tokens with 7 phrases; found: 7 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.2208, \"per_token_accuracy\": 0.9996}, \"time_spent\": \"0:00:06\", \"epochs_done\": 25, \"batches_seen\": 775, \"train_examples_seen\": 48325, \"impatience\": 2, \"patience_limit\": 5}}\n",
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:06\", \"epochs_done\": 25, \"batches_seen\": 800, \"train_examples_seen\": 49925, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 1.0596876233961438e-05}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:38.107 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 407 tokens with 10 phrases; found: 10 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 10\n",
      "\n",
      "\n",
      "I0806 14:38:38.107974 139782432462464 fmeasure.py:390] processed 407 tokens with 10 phrases; found: 10 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 10\n",
      "\n",
      "\n",
      "2019-08-06 14:38:38.294 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "I0806 14:38:38.294604 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "2019-08-06 14:38:38.296 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 170: Did not improve on the ner_f1 of 99.4792\n",
      "I0806 14:38:38.296347 139782432462464 nn_trainer.py:170] Did not improve on the ner_f1 of 99.4792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:07\", \"epochs_done\": 29, \"batches_seen\": 900, \"train_examples_seen\": 56121, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 6.457263488357512e-06}}\n",
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.2208, \"per_token_accuracy\": 0.9996}, \"time_spent\": \"0:00:07\", \"epochs_done\": 30, \"batches_seen\": 930, \"train_examples_seen\": 57990, \"impatience\": 3, \"patience_limit\": 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:38.665 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 350 tokens with 4 phrases; found: 4 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
      "\n",
      "\n",
      "I0806 14:38:38.665331 139782432462464 fmeasure.py:390] processed 350 tokens with 4 phrases; found: 4 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:07\", \"epochs_done\": 32, \"batches_seen\": 1000, \"train_examples_seen\": 62368, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 5.799743025960425e-06}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:39.126 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "I0806 14:38:39.126231 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "2019-08-06 14:38:39.127 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 170: Did not improve on the ner_f1 of 99.4792\n",
      "I0806 14:38:39.127966 139782432462464 nn_trainer.py:170] Did not improve on the ner_f1 of 99.4792\n",
      "2019-08-06 14:38:39.220 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 409 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 9\n",
      "\n",
      "\n",
      "I0806 14:38:39.220561 139782432462464 fmeasure.py:390] processed 409 tokens with 9 phrases; found: 9 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.2208, \"per_token_accuracy\": 0.9996}, \"time_spent\": \"0:00:08\", \"epochs_done\": 35, \"batches_seen\": 1085, \"train_examples_seen\": 67655, \"impatience\": 4, \"patience_limit\": 5}}\n",
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:08\", \"epochs_done\": 35, \"batches_seen\": 1100, \"train_examples_seen\": 68615, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 5.171824187542029e-06}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:39.697 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 405 tokens with 14 phrases; found: 14 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 14\n",
      "\n",
      "\n",
      "I0806 14:38:39.697935 139782432462464 fmeasure.py:390] processed 405 tokens with 14 phrases; found: 14 phrases; correct: 0.\n",
      "\n",
      "precision:  100.00%; recall:  100.00%; FB1:  100.00\n",
      "\n",
      "\tpricerange: precision:  100.00%; recall:  100.00%; F1:  100.00 14\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 64, \"metrics\": {\"ner_f1\": 100.0, \"per_token_accuracy\": 1.0}, \"time_spent\": \"0:00:08\", \"epochs_done\": 38, \"batches_seen\": 1200, \"train_examples_seen\": 74862, \"learning_rate\": 0.01, \"momentum\": null, \"loss\": 3.835173593529362e-06}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:39.948 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "I0806 14:38:39.948005 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 194 phrases; correct: 0.\n",
      "\n",
      "precision:  98.45%; recall:  100.00%; FB1:  99.22\n",
      "\n",
      "\tpricerange: precision:  98.45%; recall:  100.00%; F1:  99.22 194\n",
      "\n",
      "\n",
      "2019-08-06 14:38:39.949 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 170: Did not improve on the ner_f1 of 99.4792\n",
      "I0806 14:38:39.949785 139782432462464 nn_trainer.py:170] Did not improve on the ner_f1 of 99.4792\n",
      "2019-08-06 14:38:39.980 INFO in 'deeppavlov.core.models.lr_scheduled_model'['lr_scheduled_model'] at line 430: New learning rate dividor = 10.0\n",
      "I0806 14:38:39.980058 139782432462464 lr_scheduled_model.py:430] New learning rate dividor = 10.0\n",
      "2019-08-06 14:38:40.11 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 286: Ran out of patience\n",
      "I0806 14:38:40.011410 139782432462464 nn_trainer.py:286] Ran out of patience\n",
      "2019-08-06 14:38:40.21 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/word.dict]\n",
      "I0806 14:38:40.021934 139782432462464 simple_vocab.py:112] [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/word.dict]\n",
      "2019-08-06 14:38:40.24 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/tag.dict]\n",
      "I0806 14:38:40.024750 139782432462464 simple_vocab.py:112] [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.2208, \"per_token_accuracy\": 0.9996}, \"time_spent\": \"0:00:08\", \"epochs_done\": 40, \"batches_seen\": 1240, \"train_examples_seen\": 77320, \"impatience\": 5, \"patience_limit\": 5}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:40.695 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "I0806 14:38:40.695365 139782432462464 tf_model.py:52] [loading model from /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "2019-08-06 14:38:40.841 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 8424 tokens with 191 phrases; found: 193 phrases; correct: 0.\n",
      "\n",
      "precision:  98.96%; recall:  100.00%; FB1:  99.48\n",
      "\n",
      "\tpricerange: precision:  98.96%; recall:  100.00%; F1:  99.48 193\n",
      "\n",
      "\n",
      "I0806 14:38:40.841041 139782432462464 fmeasure.py:390] processed 8424 tokens with 191 phrases; found: 193 phrases; correct: 0.\n",
      "\n",
      "precision:  98.96%; recall:  100.00%; FB1:  99.48\n",
      "\n",
      "\tpricerange: precision:  98.96%; recall:  100.00%; F1:  99.48 193\n",
      "\n",
      "\n",
      "2019-08-06 14:38:40.911 DEBUG in 'deeppavlov.metrics.fmeasure'['fmeasure'] at line 390: processed 7797 tokens with 177 phrases; found: 178 phrases; correct: 0.\n",
      "\n",
      "precision:  99.44%; recall:  100.00%; FB1:  99.72\n",
      "\n",
      "\tpricerange: precision:  99.44%; recall:  100.00%; F1:  99.72 178\n",
      "\n",
      "\n",
      "I0806 14:38:40.911868 139782432462464 fmeasure.py:390] processed 7797 tokens with 177 phrases; found: 178 phrases; correct: 0.\n",
      "\n",
      "precision:  99.44%; recall:  100.00%; FB1:  99.72\n",
      "\n",
      "\tpricerange: precision:  99.44%; recall:  100.00%; F1:  99.72 178\n",
      "\n",
      "\n",
      "2019-08-06 14:38:40.917 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/word.dict]\n",
      "I0806 14:38:40.917828 139782432462464 simple_vocab.py:112] [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/word.dict]\n",
      "2019-08-06 14:38:40.921 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/tag.dict]\n",
      "I0806 14:38:40.921181 139782432462464 simple_vocab.py:112] [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/tag.dict]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 1444, \"metrics\": {\"ner_f1\": 99.4792, \"per_token_accuracy\": 0.9998}, \"time_spent\": \"0:00:01\"}}\n",
      "{\"test\": {\"eval_examples_count\": 1386, \"metrics\": {\"ner_f1\": 99.7183, \"per_token_accuracy\": 0.9999}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:38:41.451 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "I0806 14:38:41.451829 139782432462464 tf_model.py:52] [loading model from /home/vimary/code-projects/Pilot/examples/my_bot/model]\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import train_model\n",
    "\n",
    "train_model(ner_config, download=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags (& counts) found in the data are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\t11573\r\n",
      "B-pricerange\t268\r\n"
     ]
    }
   ],
   "source": [
    "!cat my_bot/tag.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-06 14:39:27.415 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/word.dict]\n",
      "I0806 14:39:27.415698 139782432462464 simple_vocab.py:112] [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/word.dict]\n",
      "2019-08-06 14:39:27.419 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/tag.dict]\n",
      "I0806 14:39:27.419156 139782432462464 simple_vocab.py:112] [loading vocabulary from /home/vimary/code-projects/Pilot/examples/my_bot/tag.dict]\n",
      "2019-08-06 14:39:28.147 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /home/vimary/code-projects/Pilot/examples/my_bot/model]\n",
      "I0806 14:39:28.147900 139782432462464 tf_model.py:52] [loading model from /home/vimary/code-projects/Pilot/examples/my_bot/model]\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model\n",
    "\n",
    "ner = build_model(ner_config, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['hi', 'i', 'want', 'some', 'cheap', 'food']],\n",
       " [['O', 'O', 'O', 'O', 'B-pricerange', 'O']]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(['hi i want some cheap food'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"dataset_reader\": {\n",
    "    \"class_name\": \"dstc2_reader\",\n",
    "    \"data_path\": \"{DOWNLOADS_PATH}\"\n",
    "  },\n",
    "  \"dataset_iterator\": {\n",
    "    \"class_name\": \"dialog_iterator\"\n",
    "  },\n",
    "  \"chainer\": {\n",
    "    \"in\": [\"x\"],\n",
    "    \"in_y\": [\"y\"],\n",
    "    \"out\": [\"y_predicted\"],\n",
    "    \"pipe\": [\n",
    "      {\n",
    "        \"class_name\": \"deeppavlov.models.go_bot.wrapper:DialogComponentWrapper\",\n",
    "        \"component\": {\n",
    "            \"class_name\": \"split_tokenizer\"\n",
    "        },\n",
    "        \"in\": [\"x\"],\n",
    "        \"out\": [\"x_tokens\"]\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"word_vocab\",\n",
    "        \"class_name\": \"simple_vocab\",\n",
    "        \"fit_on\": [\"x_tokens\"],\n",
    "        \"save_path\": \"{BOT_PATH}/word.dict\",\n",
    "        \"load_path\": \"{BOT_PATH}/word.dict\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"restaurant_database\",\n",
    "        \"class_name\": \"sqlite_database\",\n",
    "        \"table_name\": \"mytable\",\n",
    "        \"primary_keys\": [\"name\"],\n",
    "        \"save_path\": \"{DOWNLOADS_PATH}/db.sqlite\"\n",
    "      },\n",
    "      {\n",
    "        \"class_name\": \"go_bot\",\n",
    "        \"load_path\": \"{BOT_PATH}/model\",\n",
    "        \"save_path\": \"{BOT_PATH}/model\",\n",
    "        \"in\": [\"x\"],\n",
    "        \"in_y\": [\"y\"],\n",
    "        \"out\": [\"y_predicted\"],\n",
    "        \"main\": True,\n",
    "        \"debug\": False,\n",
    "        \"learning_rate\": 0.003,\n",
    "        \"learning_rate_drop_patience\": 5,\n",
    "        \"learning_rate_drop_div\": 10.0,\n",
    "        \"momentum\": 0.95,\n",
    "        \"optimizer\": \"tensorflow.train:AdamOptimizer\",\n",
    "        \"clip_norm\": 2.0,\n",
    "        \"dropout_rate\": 0.4,\n",
    "        \"l2_reg_coef\": 3e-4,\n",
    "        \"hidden_size\": 128,\n",
    "        \"dense_size\": 160,\n",
    "        \"word_vocab\": \"#word_vocab\",\n",
    "        \"template_path\": \"{DOWNLOADS_PATH}/templates.txt\",\n",
    "        \"template_type\": \"DualTemplate\",\n",
    "        \"database\": \"#restaurant_database\",\n",
    "        \"api_call_action\": \"api_call\",\n",
    "        \"use_action_mask\": False,\n",
    "        \"slot_filler\": {\n",
    "          \"config_path\": \"{CONFIGS_PATH}/ner/slotfill_dstc2.json\"\n",
    "        },\n",
    "        \"intent_classifier\": None,\n",
    "        \"embedder\": {\n",
    "          \"class_name\": \"glove\",\n",
    "          \"load_path\": \"{DOWNLOADS_PATH}/glove.6B.100d.txt\"\n",
    "        },\n",
    "        \"bow_embedder\": {\n",
    "          \"class_name\": \"bow\",\n",
    "          \"depth\": \"#word_vocab.__len__()\",\n",
    "          \"with_counts\": True\n",
    "        },\n",
    "        \"tokenizer\": {\n",
    "          \"class_name\": \"stream_spacy_tokenizer\",\n",
    "          \"lowercase\": False\n",
    "        },\n",
    "        \"tracker\": {\n",
    "          \"class_name\": \"featurized_tracker\",\n",
    "          \"slot_names\": [\"pricerange\", \"this\", \"area\", \"food\", \"name\"]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"train\": {\n",
    "    \"epochs\": 200,\n",
    "    \"batch_size\": 8,\n",
    "\n",
    "    \"metrics\": [\"per_item_dialog_accuracy\"],\n",
    "    \"validation_patience\": 10,\n",
    "    \"val_every_n_batches\": 15,\n",
    "\n",
    "    \"log_every_n_batches\": 15,\n",
    "    \"show_examples\": False,\n",
    "    \"evaluation_targets\": [\n",
    "      \"valid\",\n",
    "      \"test\"\n",
    "    ],\n",
    "    \"class_name\": \"nn_trainer\"\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"variables\": {\n",
    "      \"ROOT_PATH\": \".\",\n",
    "      \"DOWNLOADS_PATH\": \"{ROOT_PATH}/my_data\",\n",
    "      \"MODEL_PATH\": \"{ROOT_PATH}/my_model\",\n",
    "      \"CONFIGS_PATH\": \"{DEEPPAVLOV_PATH}/configs\"\n",
    "    },\n",
    "    \"requirements\": [\n",
    "      \"{DEEPPAVLOV_PATH}/requirements/tf.txt\",\n",
    "      \"{DEEPPAVLOV_PATH}/requirements/gensim.txt\",\n",
    "      \"{DEEPPAVLOV_PATH}/requirements/spacy.txt\",\n",
    "      \"{DEEPPAVLOV_PATH}/requirements/en_core_web_sm.txt\"\n",
    "    ],\n",
    "    \"labels\": {\n",
    "      \"telegram_utils\": \"GoalOrientedBot\",\n",
    "      \"server_utils\": \"GoalOrientedBot\"\n",
    "    },\n",
    "    \"download\": [\n",
    "      {\n",
    "        \"url\": \"http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt\",\n",
    "        \"subdir\": \"{DOWNLOADS_PATH}/embeddings\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import configs, parse_json\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dp_env)",
   "language": "python",
   "name": "dp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
